# Kafka UI: An Intuitive Interface for Apache Kafka Cluster Management

> *Team Members: Mingxin Hou, Yiren Xu, Bingyao Liu*
>

# Part I: ****Introduction, Set Up and Partitioning****

## 1. Intro and Overview

### 1.1 Intro to UI for Apache Kafka

`Kafka UI` is an open-source web application designed to provide a user-friendly interface for the management and monitoring of Apache Kafka clusters. It enables users to navigate through topics, view cluster status, inspect consumer groups, configure settings, and more, without the need to interact directly with the underlying details of the Kafka cluster.[[1]](https://github.com/provectus/kafka-ui)

### 1.2 Technical Overview

- Frontend:
  The Kafka UI project employs `TypeScript` and `React` framework, adopting a single-page application (SPA) model for UI construction. `TypeScript` use emphasizes type safety and error management during development.

- Backend:
  The backend programming language is `Java`, used with the `Spring Boot` framework to manage server-side logic, database interactions, and communication with Kafka. It conforms to a microservices architecture, supporting independent deployment and scaling of services.

- Project Management and Build Tools:
  The project utilizes `Maven` as its project management and build tool, demonstrating strict control over dependency management and build processes, ensuring consistency in builds and efficiency in project maintenance.

### 1.3 Code Overview

According to the statistics generated by the cloc tool on Linux, the Kafka UI project encompasses a multitude of programming languages, detailed as follows:

- `TypeScript` is the primary programming language of the project, consisting of 6,481 files and 325,842 lines of code, indicating the significance of the front-end component.
- `JSON` is employed for configuration files and data interchange, with 1,810 files comprising 248,555 lines of code.
- `Markdown` is utilized for documentation, represented by 1,330 files, signifying well-maintained project documentation.
- `Java` is used for backend logic, with 416 files and 35,370 lines of code, serving as the project's backend programming language.
- Languages such as `XML`, `Python`, `YAML`, `HTML`, `CSS`, and others are applied for configuration, scripting, and web page design.

The project also leverages a variety of scripting and configuration languages, including `Bourne Shell`, `Maven`, `Sass`, `ANTLR Grammar`, etc., demonstrating its multifaceted build and configuration management.

In total, the project possesses 27,946 files and 4,112,984 lines of code, displaying a vast and complex codebase that necessitates appropriate testing and maintenance strategies to ensure its robustness.

```
---------------------------------------------------------------------------------------
Language                             files          blank        comment           code
---------------------------------------------------------------------------------------
TypeScript                            6481          42985         203840         325842
JSON                                  1810            107              0         248555
Markdown                              1330          61984              0         142141
Java                                   416           5195            693          33570
XML                                     94             23             50          25261
Python                                  49           4370           7926          23036
YAML                                   198           1615            243          19008
HTML                                    14           4659          11214          18380
CSS                                     64            281             54           8626
Bourne Shell                           128            487            207           2919
Maven                                    5             44             10           1303
Sass                                     5            129              0            684
ANTLR Grammar                            1             86              3            532
Windows Module Definition                5             83              0            451
Lisp                                     2             42             38            258
C#                                       1             55              9            186
DOS Batch                                3             36              0            156
SVG                                      6              1              2            131
make                                     6             44             31            130
PHP                                      1             13             19            124
Protocol Buffers                         6             19              1             82
Bourne Again Shell                       3             13              1             51
TOML                                     1              5              0             36
Dockerfile                               3             12              6             24
SQL                                      1              2              0             22
C++                                      2             12             19             20
Nix                                      1              1              0             19
CoffeeScript                             1              1              0              0
---------------------------------------------------------------------------------------
SUM:                                 27946         396566         820149        4112984
---------------------------------------------------------------------------------------
```

## 2.Setup & Build

### 2.1 Fork & Clone to the local machine

The first thing we did is to fork the project into our own repository. The original repository was at [https://github.com/provectus/kafka-ui](https://github.com/provectus/kafka-ui), which was shown below.

![Fig 1-2-1 Fork button](Fig/Untitled%201.png)

Fig 1-2-1 Fork button

We used the button as pointed by the red arrow to fork the project, then typed the command below to clone the project by Git into the local disk.

`git clone [https://github.com/mingxin0607/kafka-ui.git](https://github.com/mingxin0607/kafka-ui.git)`

### 2.2 Build & Run

After the operations above, we would like to open the project in an IDE and try to build the project. Our team use `IntelliJ IDEA` provided by JetBrain as IDE.

#### 2.2.1 Build & Run on macOS (Docker)

Initially, we operated on a macOS platform and utilized Docker to build and execute the project. To prepare our development environment, we verified the inclusion of the following tools:

- Java 17 package or newer(for Maven and Spring Boot backend)
- Node.js and npm (for frontend application)
- Docker (for container building and running)
- Maven (for building the project including the Kafka UI backend).

#### Step 1: Backend--Build Docker Image:
- Open terminal, navigate to the project root.
- Build the project including kafka-ui-api backend:
```shell
./mvnw clean install -Pprod
```
If skipping the tests:
```shell
./mvnw clean install -Dmaven.test.skip=true -Pprod
```
To build only the kafka-ui-api:
```shell
./mvnw -f kafka-ui-api/pom.xml clean install -Pprod -DskipUIBuild=true
```
#### Step 2: Frontend:
- Navigate to frontend directory (e.g., kafka-ui-react-app).
- Install Dependencies:
```shell
npm install
```
- Build Frontend Application:
```shell
npm run build
```
#### Step 3: Running the Project:
- Run with Docker Compose:
```shell
docker-compose -f ./documentation/compose/kafka-ui.yaml up -d
```
#### Step 4: Access Kafka UI:
- Once running, visit http://localhost:8080 in a browser.

#### 2.2.2 Build & Run on Ubuntu (Without Docker)

Then built and ran the project on Ubuntu, which is an open-source operating system based on Linux. This was done without using Docker, assuming that we had already installed the prerequisites and cloned the repository.

#### Method1: Quick Project Execution (Without Building JAR):

- To run Kafka UI quickly without manually building a JAR file, execute a pre-built JAR file with this command:
```shell
java -Dspring.config.additional-location=<path-to-application-local.yml> --add-opens java.rmi/javax.rmi.ssl=ALL-UNNAMED -jar <path-to-kafka-ui-jar>
```
Replace <path-to-application-local.yml> and <path-to-kafka-ui-jar> with actual file paths. Configure Kafka cluster details in application-local.yml.

#### Method2: Manual Build and Execution (Without Docker):
- Comment out the docker-maven-plugin in kafka-ui-api/pom.xml.
- Build the JAR file with Maven:
```shell
mvn clean install
```
- Locate the built JAR (kafka-ui-api-0.0.1-SNAPSHOT.jar) in kafka-ui-api/target.
- Run the JAR file using the aforementioned command.






## Functional testing and partition testing

### Functional Testing

Functional Testing is a type of software testing that validates the software system against the functional requirements/specifications. The purpose of Functional tests is to test each function of the software application, by providing appropriate input, verifying the output against the Functional requirements.

Functional testing mainly involves black box testing and it is not concerned about the source code of the application. This testing checks User Interface, APIs, Database, Security, Client/Server communication and other functionality of the Application Under Test. The testing can be done either manually or using automation.

#### Purpose of functional testing
- Ensuring Correct Functionality

Systematic functional testing is essential to ensure that the software functions correctly according to its specifications and requirements. This helps in delivering a product that meets user expectations.

- Comprehensive Coverage

Systematic functional testing aims to provide comprehensive coverage of the entire application. This includes testing individual units, ensuring proper integration, and validating the system as a whole.

- Building User Confidence

Thorough functional testing builds confidence among users and stakeholders, assuring them that the software not only works but works reliably under various conditions.


### Partition Testing

Partition Testing is a software testing technique that divides the input data of a software unit into partitions of equivalent data from which test cases can be derived. In principle, test cases are designed to cover each partition at least once. This technique tries to define test cases that uncover classes of errors, thereby reducing the total number of test cases that must be developed. An advantage of this approach is reduction in the time required for testing software due to lesser number of test cases. 

#### Purpose of partition testing
- Efficient Testing

Partition testing allows for efficient testing by dividing the input space into equivalence classes. This reduces the number of test cases needed while ensuring that each class is adequately represented.

- Identifying Critical Input Scenarios

Not all possible inputs need to be tested individually. Partition testing helps identify critical input scenarios, allowing testers to focus on representative values that are likely to reveal defects.

- Identifying Defects Associated with Input Classes

Defects often cluster around specific input classes. Partition testing aids in identifying and addressing issues associated with different input partitions, contributing to improved software reliability.

### The feature for partition testing

We chose the class `Int32Serde` implemented at "kafka-ui-api/src/main/java/com/provectus/kafka/ui/serdes/builtin/Int32Serde.java".
It deals with serialization and deserialization of a 32-bit integer.
It implemented interface `BuiltInSerde` at "kafka-ui-api/src/main/java/com/provectus/kafka/ui/serdes/BuiltInSerde.java", which extends another interface `Serde` at "kafka-ui-serde-api/src/main/java/com/provectus/kafka/ui/serde/api/Serde.java".

### New partition tests
The input space of this feature is 32-bit integers in the form of string.
We partitioned the input space into 4 parts based on the nature of integers: zero, positive integer[1, 2147483647], negative integer[-2147483648, -1], invalid input (including all integers beyond the scope [-2147483648, 2147483647] and all invalid string that does not represent an integer).

We chose number "1234" and "2147483647" to represent the positive integer partition, number "-2147483648" to represent the negative partition and chose "null" and "2147483648" to represent invalid input. 
We included both boundaries and random representative values to cover all partitions and make sure the feature is stable at boundaries.
For valid input, after serialization and deserialization, the value should be the same. For invalid input, an exception should be thrown.

New test cases and their documents were included in "kafka-ui-api/src/test/java/com/provectus/kafka/ui/serdes/builtin/Int32SerdeTest.java". To run all JUnit tests, use the command "mvn clean test".