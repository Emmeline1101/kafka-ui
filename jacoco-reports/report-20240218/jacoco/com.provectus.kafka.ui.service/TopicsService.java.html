<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>TopicsService.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">kafka-ui-api</a> &gt; <a href="index.source.html" class="el_package">com.provectus.kafka.ui.service</a> &gt; <span class="el_source">TopicsService.java</span></div><h1>TopicsService.java</h1><pre class="source lang-java linenums">package com.provectus.kafka.ui.service;

import static java.util.stream.Collectors.toList;
import static java.util.stream.Collectors.toMap;

import com.google.common.collect.Sets;
import com.provectus.kafka.ui.config.ClustersProperties;
import com.provectus.kafka.ui.exception.TopicMetadataException;
import com.provectus.kafka.ui.exception.TopicNotFoundException;
import com.provectus.kafka.ui.exception.TopicRecreationException;
import com.provectus.kafka.ui.exception.ValidationException;
import com.provectus.kafka.ui.model.ClusterFeature;
import com.provectus.kafka.ui.model.InternalLogDirStats;
import com.provectus.kafka.ui.model.InternalPartition;
import com.provectus.kafka.ui.model.InternalPartitionsOffsets;
import com.provectus.kafka.ui.model.InternalReplica;
import com.provectus.kafka.ui.model.InternalTopic;
import com.provectus.kafka.ui.model.InternalTopicConfig;
import com.provectus.kafka.ui.model.KafkaCluster;
import com.provectus.kafka.ui.model.Metrics;
import com.provectus.kafka.ui.model.PartitionsIncreaseDTO;
import com.provectus.kafka.ui.model.PartitionsIncreaseResponseDTO;
import com.provectus.kafka.ui.model.ReplicationFactorChangeDTO;
import com.provectus.kafka.ui.model.ReplicationFactorChangeResponseDTO;
import com.provectus.kafka.ui.model.Statistics;
import com.provectus.kafka.ui.model.TopicCreationDTO;
import com.provectus.kafka.ui.model.TopicUpdateDTO;
import java.time.Duration;
import java.util.Collection;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.function.Function;
import java.util.stream.Collectors;
import lombok.RequiredArgsConstructor;
import org.apache.kafka.clients.admin.ConfigEntry;
import org.apache.kafka.clients.admin.NewPartitionReassignment;
import org.apache.kafka.clients.admin.NewPartitions;
import org.apache.kafka.clients.admin.OffsetSpec;
import org.apache.kafka.clients.admin.ProducerState;
import org.apache.kafka.clients.admin.TopicDescription;
import org.apache.kafka.common.Node;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.errors.TopicExistsException;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Mono;
import reactor.util.retry.Retry;

@Service
<span class="fc" id="L53">@RequiredArgsConstructor</span>
public class TopicsService {

  private final AdminClientService adminClientService;
  private final StatisticsCache statisticsCache;
  private final ClustersProperties clustersProperties;
  @Value(&quot;${topic.recreate.maxRetries:15}&quot;)
  private int recreateMaxRetries;
  @Value(&quot;${topic.recreate.delay.seconds:1}&quot;)
  private int recreateDelayInSeconds;
  @Value(&quot;${topic.load.after.create.maxRetries:10}&quot;)
  private int loadTopicAfterCreateRetries;
  @Value(&quot;${topic.load.after.create.delay.ms:500}&quot;)
  private int loadTopicAfterCreateDelayInMs;

  public Mono&lt;List&lt;InternalTopic&gt;&gt; loadTopics(KafkaCluster c, List&lt;String&gt; topics) {
<span class="pc bpc" id="L69" title="1 of 2 branches missed.">    if (topics.isEmpty()) {</span>
<span class="nc" id="L70">      return Mono.just(List.of());</span>
    }
<span class="fc" id="L72">    return adminClientService.get(c)</span>
<span class="fc" id="L73">        .flatMap(ac -&gt;</span>
<span class="fc" id="L74">            ac.describeTopics(topics).zipWith(ac.getTopicsConfig(topics, false),</span>
                (descriptions, configs) -&gt; {
<span class="fc" id="L76">                  statisticsCache.update(c, descriptions, configs);</span>
<span class="fc" id="L77">                  return getPartitionOffsets(descriptions, ac).map(offsets -&gt; {</span>
<span class="fc" id="L78">                    var metrics = statisticsCache.get(c);</span>
<span class="fc" id="L79">                    return createList(</span>
                        topics,
                        descriptions,
                        configs,
                        offsets,
<span class="fc" id="L84">                        metrics.getMetrics(),</span>
<span class="fc" id="L85">                        metrics.getLogDirInfo()</span>
                    );
                  });
<span class="fc" id="L88">                })).flatMap(Function.identity());</span>
  }

  private Mono&lt;InternalTopic&gt; loadTopic(KafkaCluster c, String topicName) {
<span class="fc" id="L92">    return loadTopics(c, List.of(topicName))</span>
<span class="fc" id="L93">        .flatMap(lst -&gt; lst.stream().findFirst()</span>
<span class="fc" id="L94">            .map(Mono::just)</span>
<span class="fc" id="L95">            .orElse(Mono.error(TopicNotFoundException::new)));</span>
  }

  /**
   *  After creation topic can be invisible via API for some time.
   *  To workaround this, we retyring topic loading until it becomes visible.
   */
  private Mono&lt;InternalTopic&gt; loadTopicAfterCreation(KafkaCluster c, String topicName) {
<span class="fc" id="L103">    return loadTopic(c, topicName)</span>
<span class="fc" id="L104">        .retryWhen(</span>
            Retry
<span class="fc" id="L106">                .fixedDelay(</span>
                    loadTopicAfterCreateRetries,
<span class="fc" id="L108">                    Duration.ofMillis(loadTopicAfterCreateDelayInMs)</span>
                )
<span class="fc" id="L110">                .filter(TopicNotFoundException.class::isInstance)</span>
<span class="fc" id="L111">                .onRetryExhaustedThrow((spec, sig) -&gt;</span>
<span class="nc" id="L112">                    new TopicMetadataException(</span>
<span class="nc" id="L113">                        String.format(</span>
                            &quot;Error while loading created topic '%s' - topic is not visible via API &quot;
                                + &quot;after waiting for %d ms.&quot;,
                            topicName,
<span class="nc" id="L117">                            loadTopicAfterCreateDelayInMs * loadTopicAfterCreateRetries)))</span>
        );
  }

  private List&lt;InternalTopic&gt; createList(List&lt;String&gt; orderedNames,
                                         Map&lt;String, TopicDescription&gt; descriptions,
                                         Map&lt;String, List&lt;ConfigEntry&gt;&gt; configs,
                                         InternalPartitionsOffsets partitionsOffsets,
                                         Metrics metrics,
                                         InternalLogDirStats logDirInfo) {
<span class="fc" id="L127">    return orderedNames.stream()</span>
<span class="fc" id="L128">        .filter(descriptions::containsKey)</span>
<span class="fc" id="L129">        .map(t -&gt; InternalTopic.from(</span>
<span class="fc" id="L130">            descriptions.get(t),</span>
<span class="fc" id="L131">            configs.getOrDefault(t, List.of()),</span>
            partitionsOffsets,
            metrics,
            logDirInfo,
<span class="fc" id="L135">            clustersProperties.getInternalTopicPrefix()</span>
        ))
<span class="fc" id="L137">        .collect(toList());</span>
  }

  private Mono&lt;InternalPartitionsOffsets&gt; getPartitionOffsets(Map&lt;String, TopicDescription&gt;
                                                                  descriptionsMap,
                                                              ReactiveAdminClient ac) {
<span class="fc" id="L143">    var descriptions = descriptionsMap.values();</span>
<span class="fc" id="L144">    return ac.listOffsets(descriptions, OffsetSpec.earliest())</span>
<span class="fc" id="L145">        .zipWith(ac.listOffsets(descriptions, OffsetSpec.latest()),</span>
            (earliest, latest) -&gt;
<span class="fc" id="L147">                Sets.intersection(earliest.keySet(), latest.keySet())</span>
<span class="fc" id="L148">                    .stream()</span>
<span class="fc" id="L149">                    .map(tp -&gt;</span>
<span class="fc" id="L150">                        Map.entry(tp,</span>
                            new InternalPartitionsOffsets.Offsets(
<span class="fc" id="L152">                                earliest.get(tp), latest.get(tp))))</span>
<span class="fc" id="L153">                    .collect(toMap(Map.Entry::getKey, Map.Entry::getValue)))</span>
<span class="fc" id="L154">        .map(InternalPartitionsOffsets::new);</span>
  }

  public Mono&lt;InternalTopic&gt; getTopicDetails(KafkaCluster cluster, String topicName) {
<span class="fc" id="L158">    return loadTopic(cluster, topicName);</span>
  }

  public Mono&lt;List&lt;ConfigEntry&gt;&gt; getTopicConfigs(KafkaCluster cluster, String topicName) {
    // there 2 case that we cover here:
    // 1. topic not found/visible - describeTopic() will be empty and we will throw TopicNotFoundException
    // 2. topic is visible, but we don't have DESCRIBE_CONFIG permission - we should return empty list
<span class="fc" id="L165">    return adminClientService.get(cluster)</span>
<span class="fc" id="L166">        .flatMap(ac -&gt; ac.describeTopic(topicName)</span>
<span class="fc" id="L167">            .switchIfEmpty(Mono.error(new TopicNotFoundException()))</span>
<span class="fc" id="L168">            .then(ac.getTopicsConfig(List.of(topicName), true))</span>
<span class="fc" id="L169">            .map(m -&gt; m.values().stream().findFirst().orElse(List.of())));</span>
  }

  private Mono&lt;InternalTopic&gt; createTopic(KafkaCluster c, ReactiveAdminClient adminClient, TopicCreationDTO topicData) {
<span class="fc" id="L173">    return adminClient.createTopic(</span>
<span class="fc" id="L174">            topicData.getName(),</span>
<span class="fc" id="L175">            topicData.getPartitions(),</span>
<span class="fc" id="L176">            topicData.getReplicationFactor(),</span>
<span class="fc" id="L177">            topicData.getConfigs())</span>
<span class="fc" id="L178">        .thenReturn(topicData)</span>
<span class="fc" id="L179">        .onErrorMap(t -&gt; new TopicMetadataException(t.getMessage(), t))</span>
<span class="fc" id="L180">        .then(loadTopicAfterCreation(c, topicData.getName()));</span>
  }

  public Mono&lt;InternalTopic&gt; createTopic(KafkaCluster cluster, TopicCreationDTO topicCreation) {
<span class="fc" id="L184">    return adminClientService.get(cluster)</span>
<span class="fc" id="L185">        .flatMap(ac -&gt; createTopic(cluster, ac, topicCreation));</span>
  }

  public Mono&lt;InternalTopic&gt; recreateTopic(KafkaCluster cluster, String topicName) {
<span class="fc" id="L189">    return loadTopic(cluster, topicName)</span>
<span class="fc" id="L190">        .flatMap(t -&gt; deleteTopic(cluster, topicName)</span>
<span class="fc" id="L191">            .thenReturn(t)</span>
<span class="fc" id="L192">            .delayElement(Duration.ofSeconds(recreateDelayInSeconds))</span>
<span class="fc" id="L193">            .flatMap(topic -&gt;</span>
<span class="fc" id="L194">                adminClientService.get(cluster)</span>
<span class="fc" id="L195">                    .flatMap(ac -&gt;</span>
<span class="fc" id="L196">                        ac.createTopic(</span>
<span class="fc" id="L197">                                topic.getName(),</span>
<span class="fc" id="L198">                                topic.getPartitionCount(),</span>
<span class="fc" id="L199">                                topic.getReplicationFactor(),</span>
<span class="fc" id="L200">                                topic.getTopicConfigs()</span>
<span class="fc" id="L201">                                    .stream()</span>
<span class="fc" id="L202">                                    .collect(Collectors.toMap(InternalTopicConfig::getName,</span>
                                        InternalTopicConfig::getValue))
                            )
<span class="fc" id="L205">                            .thenReturn(topicName)</span>
                    )
<span class="fc" id="L207">                    .retryWhen(</span>
<span class="fc" id="L208">                        Retry.fixedDelay(recreateMaxRetries, Duration.ofSeconds(recreateDelayInSeconds))</span>
<span class="fc" id="L209">                            .filter(TopicExistsException.class::isInstance)</span>
<span class="fc" id="L210">                            .onRetryExhaustedThrow((a, b) -&gt;</span>
<span class="nc" id="L211">                                new TopicRecreationException(topicName,</span>
                                    recreateMaxRetries * recreateDelayInSeconds))
                    )
<span class="fc" id="L214">                    .flatMap(a -&gt; loadTopicAfterCreation(cluster, topicName))</span>
            )
        );
  }

  private Mono&lt;InternalTopic&gt; updateTopic(KafkaCluster cluster,
                                          String topicName,
                                          TopicUpdateDTO topicUpdate) {
<span class="fc" id="L222">    return adminClientService.get(cluster)</span>
<span class="fc" id="L223">        .flatMap(ac -&gt;</span>
<span class="fc" id="L224">            ac.updateTopicConfig(topicName, topicUpdate.getConfigs())</span>
<span class="fc" id="L225">                .then(loadTopic(cluster, topicName)));</span>
  }

  public Mono&lt;InternalTopic&gt; updateTopic(KafkaCluster cl, String topicName,
                                    Mono&lt;TopicUpdateDTO&gt; topicUpdate) {
<span class="fc" id="L230">    return topicUpdate</span>
<span class="fc" id="L231">        .flatMap(t -&gt; updateTopic(cl, topicName, t));</span>
  }

  private Mono&lt;InternalTopic&gt; changeReplicationFactor(
      KafkaCluster cluster,
      ReactiveAdminClient adminClient,
      String topicName,
      Map&lt;TopicPartition, Optional&lt;NewPartitionReassignment&gt;&gt; reassignments
  ) {
<span class="nc" id="L240">    return adminClient.alterPartitionReassignments(reassignments)</span>
<span class="nc" id="L241">        .then(loadTopic(cluster, topicName));</span>
  }

  /**
   * Change topic replication factor, works on brokers versions 5.4.x and higher
   */
  public Mono&lt;ReplicationFactorChangeResponseDTO&gt; changeReplicationFactor(
      KafkaCluster cluster,
      String topicName,
      ReplicationFactorChangeDTO replicationFactorChange) {
<span class="nc" id="L251">    return loadTopic(cluster, topicName).flatMap(topic -&gt; adminClientService.get(cluster)</span>
<span class="nc" id="L252">        .flatMap(ac -&gt; {</span>
<span class="nc" id="L253">          Integer actual = topic.getReplicationFactor();</span>
<span class="nc" id="L254">          Integer requested = replicationFactorChange.getTotalReplicationFactor();</span>
<span class="nc" id="L255">          Integer brokersCount = statisticsCache.get(cluster).getClusterDescription()</span>
<span class="nc" id="L256">              .getNodes().size();</span>

<span class="nc bnc" id="L258" title="All 2 branches missed.">          if (requested.equals(actual)) {</span>
<span class="nc" id="L259">            return Mono.error(</span>
                new ValidationException(
<span class="nc" id="L261">                    String.format(&quot;Topic already has replicationFactor %s.&quot;, actual)));</span>
          }
<span class="nc bnc" id="L263" title="All 2 branches missed.">          if (requested &lt;= 0) {</span>
<span class="nc" id="L264">            return Mono.error(</span>
                new ValidationException(
<span class="nc" id="L266">                    String.format(&quot;Requested replication factor (%s) should be greater or equal to 1.&quot;, requested)));</span>
          }
<span class="nc bnc" id="L268" title="All 2 branches missed.">          if (requested &gt; brokersCount) {</span>
<span class="nc" id="L269">            return Mono.error(</span>
                new ValidationException(
<span class="nc" id="L271">                    String.format(&quot;Requested replication factor %s more than brokers count %s.&quot;,</span>
                        requested, brokersCount)));
          }
<span class="nc" id="L274">          return changeReplicationFactor(cluster, ac, topicName,</span>
<span class="nc" id="L275">              getPartitionsReassignments(cluster, topic,</span>
                  replicationFactorChange));
        })
<span class="nc" id="L278">        .map(t -&gt; new ReplicationFactorChangeResponseDTO()</span>
<span class="nc" id="L279">            .topicName(t.getName())</span>
<span class="nc" id="L280">            .totalReplicationFactor(t.getReplicationFactor())));</span>
  }

  private Map&lt;TopicPartition, Optional&lt;NewPartitionReassignment&gt;&gt; getPartitionsReassignments(
      KafkaCluster cluster,
      InternalTopic topic,
      ReplicationFactorChangeDTO replicationFactorChange) {
    // Current assignment map (Partition number -&gt; List of brokers)
<span class="nc" id="L288">    Map&lt;Integer, List&lt;Integer&gt;&gt; currentAssignment = getCurrentAssignment(topic);</span>
    // Brokers map (Broker id -&gt; count)
<span class="nc" id="L290">    Map&lt;Integer, Integer&gt; brokersUsage = getBrokersMap(cluster, currentAssignment);</span>
<span class="nc" id="L291">    int currentReplicationFactor = topic.getReplicationFactor();</span>

    // If we should to increase Replication factor
<span class="nc bnc" id="L294" title="All 2 branches missed.">    if (replicationFactorChange.getTotalReplicationFactor() &gt; currentReplicationFactor) {</span>
      // For each partition
<span class="nc bnc" id="L296" title="All 2 branches missed.">      for (var assignmentList : currentAssignment.values()) {</span>
        // Get brokers list sorted by usage
<span class="nc" id="L298">        var brokers = brokersUsage.entrySet().stream()</span>
<span class="nc" id="L299">            .sorted(Map.Entry.comparingByValue())</span>
<span class="nc" id="L300">            .map(Map.Entry::getKey)</span>
<span class="nc" id="L301">            .collect(toList());</span>

        // Iterate brokers and try to add them in assignment
        // while partition replicas count != requested replication factor
<span class="nc bnc" id="L305" title="All 2 branches missed.">        for (Integer broker : brokers) {</span>
<span class="nc bnc" id="L306" title="All 2 branches missed.">          if (!assignmentList.contains(broker)) {</span>
<span class="nc" id="L307">            assignmentList.add(broker);</span>
<span class="nc" id="L308">            brokersUsage.merge(broker, 1, Integer::sum);</span>
          }
<span class="nc bnc" id="L310" title="All 2 branches missed.">          if (assignmentList.size() == replicationFactorChange.getTotalReplicationFactor()) {</span>
<span class="nc" id="L311">            break;</span>
          }
<span class="nc" id="L313">        }</span>
<span class="nc bnc" id="L314" title="All 2 branches missed.">        if (assignmentList.size() != replicationFactorChange.getTotalReplicationFactor()) {</span>
<span class="nc" id="L315">          throw new ValidationException(&quot;Something went wrong during adding replicas&quot;);</span>
        }
<span class="nc" id="L317">      }</span>

      // If we should to decrease Replication factor
<span class="nc bnc" id="L320" title="All 2 branches missed.">    } else if (replicationFactorChange.getTotalReplicationFactor() &lt; currentReplicationFactor) {</span>
<span class="nc bnc" id="L321" title="All 2 branches missed.">      for (Map.Entry&lt;Integer, List&lt;Integer&gt;&gt; assignmentEntry : currentAssignment.entrySet()) {</span>
<span class="nc" id="L322">        var partition = assignmentEntry.getKey();</span>
<span class="nc" id="L323">        var brokers = assignmentEntry.getValue();</span>

        // Get brokers list sorted by usage in reverse order
<span class="nc" id="L326">        var brokersUsageList = brokersUsage.entrySet().stream()</span>
<span class="nc" id="L327">            .sorted(Map.Entry.comparingByValue(Comparator.reverseOrder()))</span>
<span class="nc" id="L328">            .map(Map.Entry::getKey)</span>
<span class="nc" id="L329">            .collect(toList());</span>

        // Iterate brokers and try to remove them from assignment
        // while partition replicas count != requested replication factor
<span class="nc bnc" id="L333" title="All 2 branches missed.">        for (Integer broker : brokersUsageList) {</span>
          // Check is the broker the leader of partition
<span class="nc" id="L335">          if (!topic.getPartitions().get(partition).getLeader()</span>
<span class="nc bnc" id="L336" title="All 2 branches missed.">              .equals(broker)) {</span>
<span class="nc" id="L337">            brokers.remove(broker);</span>
<span class="nc" id="L338">            brokersUsage.merge(broker, -1, Integer::sum);</span>
          }
<span class="nc bnc" id="L340" title="All 2 branches missed.">          if (brokers.size() == replicationFactorChange.getTotalReplicationFactor()) {</span>
<span class="nc" id="L341">            break;</span>
          }
<span class="nc" id="L343">        }</span>
<span class="nc bnc" id="L344" title="All 2 branches missed.">        if (brokers.size() != replicationFactorChange.getTotalReplicationFactor()) {</span>
<span class="nc" id="L345">          throw new ValidationException(&quot;Something went wrong during removing replicas&quot;);</span>
        }
<span class="nc" id="L347">      }</span>
    } else {
<span class="nc" id="L349">      throw new ValidationException(&quot;Replication factor already equals requested&quot;);</span>
    }

    // Return result map
<span class="nc" id="L353">    return currentAssignment.entrySet().stream().collect(toMap(</span>
<span class="nc" id="L354">        e -&gt; new TopicPartition(topic.getName(), e.getKey()),</span>
<span class="nc" id="L355">        e -&gt; Optional.of(new NewPartitionReassignment(e.getValue()))</span>
    ));
  }

  private Map&lt;Integer, List&lt;Integer&gt;&gt; getCurrentAssignment(InternalTopic topic) {
<span class="nc" id="L360">    return topic.getPartitions().values().stream()</span>
<span class="nc" id="L361">        .collect(toMap(</span>
            InternalPartition::getPartition,
<span class="nc" id="L363">            p -&gt; p.getReplicas().stream()</span>
<span class="nc" id="L364">                .map(InternalReplica::getBroker)</span>
<span class="nc" id="L365">                .collect(toList())</span>
        ));
  }

  private Map&lt;Integer, Integer&gt; getBrokersMap(KafkaCluster cluster,
                                              Map&lt;Integer, List&lt;Integer&gt;&gt; currentAssignment) {
<span class="nc" id="L371">    Map&lt;Integer, Integer&gt; result = statisticsCache.get(cluster).getClusterDescription().getNodes()</span>
<span class="nc" id="L372">        .stream()</span>
<span class="nc" id="L373">        .map(Node::id)</span>
<span class="nc" id="L374">        .collect(toMap(</span>
<span class="nc" id="L375">            c -&gt; c,</span>
<span class="nc" id="L376">            c -&gt; 0</span>
        ));
<span class="nc" id="L378">    currentAssignment.values().forEach(brokers -&gt; brokers</span>
<span class="nc" id="L379">        .forEach(broker -&gt; result.put(broker, result.get(broker) + 1)));</span>

<span class="nc" id="L381">    return result;</span>
  }

  public Mono&lt;PartitionsIncreaseResponseDTO&gt; increaseTopicPartitions(
      KafkaCluster cluster,
      String topicName,
      PartitionsIncreaseDTO partitionsIncrease) {
<span class="fc" id="L388">    return loadTopic(cluster, topicName).flatMap(topic -&gt;</span>
<span class="fc" id="L389">        adminClientService.get(cluster).flatMap(ac -&gt; {</span>
<span class="fc" id="L390">          Integer actualCount = topic.getPartitionCount();</span>
<span class="fc" id="L391">          Integer requestedCount = partitionsIncrease.getTotalPartitionsCount();</span>

<span class="pc bpc" id="L393" title="1 of 2 branches missed.">          if (requestedCount &lt; actualCount) {</span>
<span class="nc" id="L394">            return Mono.error(</span>
<span class="nc" id="L395">                new ValidationException(String.format(</span>
                    &quot;Topic currently has %s partitions, which is higher than the requested %s.&quot;,
                    actualCount, requestedCount)));
          }
<span class="pc bpc" id="L399" title="1 of 2 branches missed.">          if (requestedCount.equals(actualCount)) {</span>
<span class="nc" id="L400">            return Mono.error(</span>
                new ValidationException(
<span class="nc" id="L402">                    String.format(&quot;Topic already has %s partitions.&quot;, actualCount)));</span>
          }

<span class="fc" id="L405">          Map&lt;String, NewPartitions&gt; newPartitionsMap = Collections.singletonMap(</span>
              topicName,
<span class="fc" id="L407">              NewPartitions.increaseTo(partitionsIncrease.getTotalPartitionsCount())</span>
          );
<span class="fc" id="L409">          return ac.createPartitions(newPartitionsMap)</span>
<span class="fc" id="L410">              .then(loadTopic(cluster, topicName));</span>
<span class="fc" id="L411">        }).map(t -&gt; new PartitionsIncreaseResponseDTO()</span>
<span class="fc" id="L412">            .topicName(t.getName())</span>
<span class="fc" id="L413">            .totalPartitionsCount(t.getPartitionCount())</span>
        )
    );
  }

  public Mono&lt;Void&gt; deleteTopic(KafkaCluster cluster, String topicName) {
<span class="pc bpc" id="L419" title="1 of 2 branches missed.">    if (statisticsCache.get(cluster).getFeatures().contains(ClusterFeature.TOPIC_DELETION)) {</span>
<span class="fc" id="L420">      return adminClientService.get(cluster).flatMap(c -&gt; c.deleteTopic(topicName))</span>
<span class="fc" id="L421">          .doOnSuccess(t -&gt; statisticsCache.onTopicDelete(cluster, topicName));</span>
    } else {
<span class="nc" id="L423">      return Mono.error(new ValidationException(&quot;Topic deletion restricted&quot;));</span>
    }
  }

  public Mono&lt;InternalTopic&gt; cloneTopic(
      KafkaCluster cluster, String topicName, String newTopicName) {
<span class="fc" id="L429">    return loadTopic(cluster, topicName).flatMap(topic -&gt;</span>
<span class="fc" id="L430">        adminClientService.get(cluster)</span>
<span class="fc" id="L431">            .flatMap(ac -&gt;</span>
<span class="fc" id="L432">                ac.createTopic(</span>
                    newTopicName,
<span class="fc" id="L434">                    topic.getPartitionCount(),</span>
<span class="fc" id="L435">                    topic.getReplicationFactor(),</span>
<span class="fc" id="L436">                    topic.getTopicConfigs()</span>
<span class="fc" id="L437">                        .stream()</span>
<span class="fc" id="L438">                        .collect(Collectors</span>
<span class="fc" id="L439">                            .toMap(InternalTopicConfig::getName, InternalTopicConfig::getValue))</span>
                )
<span class="fc" id="L441">            ).thenReturn(newTopicName)</span>
<span class="fc" id="L442">            .flatMap(a -&gt; loadTopicAfterCreation(cluster, newTopicName))</span>
    );
  }

  public Mono&lt;List&lt;InternalTopic&gt;&gt; getTopicsForPagination(KafkaCluster cluster) {
<span class="nc" id="L447">    Statistics stats = statisticsCache.get(cluster);</span>
<span class="nc" id="L448">    return filterExisting(cluster, stats.getTopicDescriptions().keySet())</span>
<span class="nc" id="L449">        .map(lst -&gt; lst.stream()</span>
<span class="nc" id="L450">            .map(topicName -&gt;</span>
<span class="nc" id="L451">                InternalTopic.from(</span>
<span class="nc" id="L452">                    stats.getTopicDescriptions().get(topicName),</span>
<span class="nc" id="L453">                    stats.getTopicConfigs().getOrDefault(topicName, List.of()),</span>
<span class="nc" id="L454">                    InternalPartitionsOffsets.empty(),</span>
<span class="nc" id="L455">                    stats.getMetrics(),</span>
<span class="nc" id="L456">                    stats.getLogDirInfo(),</span>
<span class="nc" id="L457">                    clustersProperties.getInternalTopicPrefix()</span>
                    ))
<span class="nc" id="L459">            .collect(toList())</span>
        );
  }

  public Mono&lt;Map&lt;TopicPartition, List&lt;ProducerState&gt;&gt;&gt; getActiveProducersState(KafkaCluster cluster, String topic) {
<span class="nc" id="L464">    return adminClientService.get(cluster)</span>
<span class="nc" id="L465">        .flatMap(ac -&gt; ac.getActiveProducersState(topic));</span>
  }

  private Mono&lt;List&lt;String&gt;&gt; filterExisting(KafkaCluster cluster, Collection&lt;String&gt; topics) {
<span class="nc" id="L469">    return adminClientService.get(cluster)</span>
<span class="nc" id="L470">        .flatMap(ac -&gt; ac.listTopics(true))</span>
<span class="nc" id="L471">        .map(existing -&gt; existing</span>
<span class="nc" id="L472">            .stream()</span>
<span class="nc" id="L473">            .filter(topics::contains)</span>
<span class="nc" id="L474">            .collect(toList()));</span>
  }

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.10.202304240956</span></div></body></html>