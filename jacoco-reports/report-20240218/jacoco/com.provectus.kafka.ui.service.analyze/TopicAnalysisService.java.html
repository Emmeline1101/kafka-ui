<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>TopicAnalysisService.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">kafka-ui-api</a> &gt; <a href="index.source.html" class="el_package">com.provectus.kafka.ui.service.analyze</a> &gt; <span class="el_source">TopicAnalysisService.java</span></div><h1>TopicAnalysisService.java</h1><pre class="source lang-java linenums">package com.provectus.kafka.ui.service.analyze;

import static com.provectus.kafka.ui.model.SeekTypeDTO.BEGINNING;

import com.provectus.kafka.ui.emitter.EnhancedConsumer;
import com.provectus.kafka.ui.emitter.SeekOperations;
import com.provectus.kafka.ui.exception.TopicAnalysisException;
import com.provectus.kafka.ui.model.ConsumerPosition;
import com.provectus.kafka.ui.model.KafkaCluster;
import com.provectus.kafka.ui.model.TopicAnalysisDTO;
import com.provectus.kafka.ui.service.ConsumerGroupService;
import com.provectus.kafka.ui.service.TopicsService;
import java.io.Closeable;
import java.time.Duration;
import java.time.Instant;
import java.util.HashMap;
import java.util.Map;
import java.util.Optional;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.errors.InterruptException;
import org.apache.kafka.common.errors.WakeupException;
import org.springframework.stereotype.Component;
import reactor.core.publisher.Mono;
import reactor.core.scheduler.Scheduler;
import reactor.core.scheduler.Schedulers;


<span class="fc" id="L30">@Slf4j</span>
@Component
<span class="fc" id="L32">@RequiredArgsConstructor</span>
public class TopicAnalysisService {

<span class="fc" id="L35">  private static final Scheduler SCHEDULER = Schedulers.newBoundedElastic(</span>
      Schedulers.DEFAULT_BOUNDED_ELASTIC_SIZE,
      Schedulers.DEFAULT_BOUNDED_ELASTIC_QUEUESIZE,
      &quot;topic-analysis-tasks&quot;,
      10, //ttl for idle threads (in sec)
      true //daemon
  );

<span class="fc" id="L43">  private final AnalysisTasksStore analysisTasksStore = new AnalysisTasksStore();</span>

  private final TopicsService topicsService;
  private final ConsumerGroupService consumerGroupService;

  public Mono&lt;Void&gt; analyze(KafkaCluster cluster, String topicName) {
<span class="fc" id="L49">    return topicsService.getTopicDetails(cluster, topicName)</span>
<span class="fc" id="L50">        .doOnNext(topic -&gt; startAnalysis(cluster, topicName))</span>
<span class="fc" id="L51">        .then();</span>
  }

  private synchronized void startAnalysis(KafkaCluster cluster, String topic) {
<span class="fc" id="L55">    var topicId = new TopicIdentity(cluster, topic);</span>
<span class="pc bpc" id="L56" title="1 of 2 branches missed.">    if (analysisTasksStore.isAnalysisInProgress(topicId)) {</span>
<span class="nc" id="L57">      throw new TopicAnalysisException(&quot;Topic is already analyzing&quot;);</span>
    }
<span class="fc" id="L59">    var task = new AnalysisTask(cluster, topicId);</span>
<span class="fc" id="L60">    analysisTasksStore.registerNewTask(topicId, task);</span>
<span class="fc" id="L61">    SCHEDULER.schedule(task);</span>
<span class="fc" id="L62">  }</span>

  public void cancelAnalysis(KafkaCluster cluster, String topicName) {
<span class="nc" id="L65">    analysisTasksStore.cancelAnalysis(new TopicIdentity(cluster, topicName));</span>
<span class="nc" id="L66">  }</span>

  public Optional&lt;TopicAnalysisDTO&gt; getTopicAnalysis(KafkaCluster cluster, String topicName) {
<span class="fc" id="L69">    return analysisTasksStore.getTopicAnalysis(new TopicIdentity(cluster, topicName));</span>
  }

  class AnalysisTask implements Runnable, Closeable {

<span class="fc" id="L74">    private final Instant startedAt = Instant.now();</span>

    private final TopicIdentity topicId;

<span class="fc" id="L78">    private final TopicAnalysisStats totalStats = new TopicAnalysisStats();</span>
<span class="fc" id="L79">    private final Map&lt;Integer, TopicAnalysisStats&gt; partitionStats = new HashMap&lt;&gt;();</span>

    private final EnhancedConsumer consumer;

<span class="fc" id="L83">    AnalysisTask(KafkaCluster cluster, TopicIdentity topicId) {</span>
<span class="fc" id="L84">      this.topicId = topicId;</span>
<span class="fc" id="L85">      this.consumer = consumerGroupService.createConsumer(</span>
          cluster,
          // to improve polling throughput
<span class="fc" id="L88">          Map.of(</span>
              ConsumerConfig.RECEIVE_BUFFER_CONFIG, &quot;-1&quot;, //let OS tune buffer size
              ConsumerConfig.MAX_POLL_RECORDS_CONFIG, &quot;100000&quot;
          )
      );
<span class="fc" id="L93">    }</span>

    @Override
    public void close() {
<span class="nc" id="L97">      consumer.wakeup();</span>
<span class="nc" id="L98">    }</span>

    @Override
    public void run() {
      try {
<span class="fc" id="L103">        log.info(&quot;Starting {} topic analysis&quot;, topicId);</span>
<span class="fc" id="L104">        consumer.partitionsFor(topicId.topicName)</span>
<span class="fc" id="L105">            .forEach(tp -&gt; partitionStats.put(tp.partition(), new TopicAnalysisStats()));</span>

<span class="fc" id="L107">        var seekOperations = SeekOperations.create(consumer, new ConsumerPosition(BEGINNING, topicId.topicName, null));</span>
<span class="fc" id="L108">        long summaryOffsetsRange = seekOperations.summaryOffsetsRange();</span>
<span class="fc" id="L109">        seekOperations.assignAndSeekNonEmptyPartitions();</span>

<span class="fc bfc" id="L111" title="All 2 branches covered.">        while (!seekOperations.assignedPartitionsFullyPolled()) {</span>
<span class="fc" id="L112">          var polled = consumer.pollEnhanced(Duration.ofSeconds(3));</span>
<span class="fc" id="L113">          polled.forEach(r -&gt; {</span>
<span class="fc" id="L114">            totalStats.apply(r);</span>
<span class="fc" id="L115">            partitionStats.get(r.partition()).apply(r);</span>
<span class="fc" id="L116">          });</span>
<span class="fc" id="L117">          updateProgress(seekOperations.offsetsProcessedFromSeek(), summaryOffsetsRange);</span>
<span class="fc" id="L118">        }</span>
<span class="fc" id="L119">        analysisTasksStore.setAnalysisResult(topicId, startedAt, totalStats, partitionStats);</span>
<span class="fc" id="L120">        log.info(&quot;{} topic analysis finished&quot;, topicId);</span>
<span class="nc" id="L121">      } catch (WakeupException | InterruptException cancelException) {</span>
<span class="nc" id="L122">        log.info(&quot;{} topic analysis stopped&quot;, topicId);</span>
        // calling cancel for cases when our thread was interrupted by some non-user cancellation reason
<span class="nc" id="L124">        analysisTasksStore.cancelAnalysis(topicId);</span>
<span class="nc" id="L125">      } catch (Throwable th) {</span>
<span class="nc" id="L126">        log.error(&quot;Error analyzing topic {}&quot;, topicId, th);</span>
<span class="nc" id="L127">        analysisTasksStore.setAnalysisError(topicId, startedAt, th);</span>
      } finally {
<span class="fc" id="L129">        consumer.close();</span>
      }
<span class="fc" id="L131">    }</span>

    private void updateProgress(long processedOffsets, long summaryOffsetsRange) {
<span class="pc bpc" id="L134" title="2 of 4 branches missed.">      if (processedOffsets &gt; 0 &amp;&amp; summaryOffsetsRange != 0) {</span>
<span class="fc" id="L135">        analysisTasksStore.updateProgress(</span>
            topicId,
<span class="fc" id="L137">            totalStats.totalMsgs,</span>
            totalStats.keysSize.sum + totalStats.valuesSize.sum,
<span class="fc" id="L139">            Math.min(100.0, (((double) processedOffsets) / summaryOffsetsRange) * 100)</span>
        );
      }
<span class="fc" id="L142">    }</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.10.202304240956</span></div></body></html>